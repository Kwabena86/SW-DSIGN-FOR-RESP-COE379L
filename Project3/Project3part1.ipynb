{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bf1c2a0-9033-4e65-b497-f8e06df7b9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m209.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/site-packages (from opencv-python) (1.26.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bfd6800-9726-4b5f-bd55-b375fc1a4e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m210.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/site-packages (from opencv-python-headless) (1.26.3)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.9.0.80\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d4df7-e29b-4943-9144-2ae2b59466b4",
   "metadata": {},
   "source": [
    "### PART 1. Data preprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376dbf97-8c96-4887-bf65-bfd84984db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6db624a-e50f-464a-9137-c277d0acff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(\"data_all_modified/train\")\n",
    "    shutil.rmtree(\"data_all_modified/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54d63d7f-5d39-4d11-8c5a-4bd7d366e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ensure directories exist\n",
    "from pathlib import Path\n",
    "Path(\"data_all_modified-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data_all_modified-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data_all_modified-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dd832a4-69b7-49f4-9111-28b63ae3dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need paths of images for individual classes so we can copy them in the new directories that we created above\n",
    "all_damage_file_paths = os.listdir('data_all_modified/damage')\n",
    "all_no_damage_file_paths = os.listdir('data_all_modified/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04094202-bd21-47f3-93df-de07ea7a7611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c512fa63-30a6-4c28-acbb-8d4ef4ba515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  13611\n",
      "Files in train/no_damage:  6855\n",
      "Files in test/damage:  13611\n",
      "Files in test/no_damage:  6855\n"
     ]
    }
   ],
   "source": [
    "# ensure to copy the images to the directories\n",
    "import shutil\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/damage', p), os.path.join('data_all_modified-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data_all_modified/no_damage', p), os.path.join('data_all_modified-split/test/no_damage', p) )\n",
    "\n",
    "# check counts:\n",
    "print(\"Files in train/damage: \", len(os.listdir(\"data_all_modified-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"data_all_modified-split/train/no_damage\")))\n",
    "\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"data_all_modified-split/train/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"data_all_modified-split/train/no_damage\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddc82708-31ad-4458-951d-b58421cc581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20466 files belonging to 2 classes.\n",
      "Using 16373 files for training.\n",
      "Using 4093 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "train_data_dir = 'data_all_modified-split/train'\n",
    "\n",
    "batch_size = 32\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10f5a06f-4201-4218-a05b-541a39fe95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7674 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data_all_modified-split/test'\n",
    "\n",
    "batch_size = 2\n",
    "# target image size\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# note that subset=\"training\", \"validation\", \"both\", and dictates which dataset is returned\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6abb09-472e-4f1c-b76e-827c374ab696",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PART 2. Model design, training, and evaluation. Exploring different model architectures, and identifying the model with high accuracy and validation accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d4465-8741-41bd-be4f-adf81d3769d6",
   "metadata": {},
   "source": [
    "### Building A Dense ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "307ff43f-f0d6-4a69-97b2-8cd99b987d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 64, 64, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 64, 64, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 32, 32, 32)        0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               819300    \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 84)                8484      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 857458 (3.27 MB)\n",
      "Trainable params: 857458 (3.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "\n",
    "# Intializing a sequential model\n",
    "model_cnn = models.Sequential()\n",
    "\n",
    "# Adding first conv layer with 64 filters and kernel size 3x3 , padding 'same' provides the output size same as the input size\n",
    "model_cnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=(128,128,3)))\n",
    "\n",
    "# Adding max pooling to reduce the size of output of first conv layer\n",
    "model_cnn.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "model_cnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "model_cnn.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "model_cnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"))\n",
    "model_cnn.add(layers.MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "# flattening the output of the conv layer after max pooling to make it ready for creating dense connections\n",
    "model_cnn.add(layers.Flatten())\n",
    "\n",
    "# Adding a fully connected dense layer with 100 neurons\n",
    "model_cnn.add(layers.Dense(100, activation='relu'))\n",
    "\n",
    "# Adding a fully connected dense layer with 84 neurons\n",
    "model_cnn.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Adding the output layer with * neurons and activation functions as softmax since this is a multi-class classification problem\n",
    "model_cnn.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "# RMSprop (Root Mean Square Propagation) is commonly used in training deep neural networks.\n",
    "model_cnn.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95b1fbb6-cbc3-4b3b-878f-50eea15206a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/512 [================>.............] - ETA: 53s - loss: 0.6053 - accuracy: 0.6930"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#fit the model from image generator\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_cnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_rescale_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rescale_ds\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#fit the model from image generator\n",
    "history = model_cnn.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f466a4-5aa5-4d92-aa1d-474d6cb48773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9521688222885132"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_cnn.evaluate(test_rescale_ds, verbose=0)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186049cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.save(\"hurricane_lenet.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445a7901-72f8-46b8-a886-c41e0398a4fe",
   "metadata": {},
   "source": [
    "### The Lenet-5 CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6c12c-4dc8-4e59-9016-22d721ffc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 126, 126, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 63, 63, 6)         0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 61, 61, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 30, 30, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               1728120   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1739587 (6.64 MB)\n",
      "Trainable params: 1739587 (6.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "model_lenet5.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a664f7-b1e4-4177-ab7a-8551555b27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "533/533 [==============================] - 32s 55ms/step - loss: 0.6258 - accuracy: 0.6806 - val_loss: 0.5822 - val_accuracy: 0.6782\n",
      "Epoch 2/20\n",
      "533/533 [==============================] - 30s 57ms/step - loss: 0.5373 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7054\n",
      "Epoch 3/20\n",
      "533/533 [==============================] - 31s 57ms/step - loss: 0.4623 - accuracy: 0.7930 - val_loss: 0.4261 - val_accuracy: 0.8213\n",
      "Epoch 4/20\n",
      "533/533 [==============================] - 31s 58ms/step - loss: 0.4328 - accuracy: 0.8144 - val_loss: 0.4249 - val_accuracy: 0.8424\n",
      "Epoch 5/20\n",
      "533/533 [==============================] - 32s 59ms/step - loss: 0.4149 - accuracy: 0.8228 - val_loss: 0.4300 - val_accuracy: 0.8374\n",
      "Epoch 6/20\n",
      "533/533 [==============================] - 33s 61ms/step - loss: 0.3951 - accuracy: 0.8374 - val_loss: 0.3784 - val_accuracy: 0.8506\n",
      "Epoch 7/20\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.3751 - accuracy: 0.8498 - val_loss: 0.3671 - val_accuracy: 0.8517\n",
      "Epoch 8/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.3583 - accuracy: 0.8577 - val_loss: 0.3704 - val_accuracy: 0.8473\n",
      "Epoch 9/20\n",
      "533/533 [==============================] - 30s 56ms/step - loss: 0.3430 - accuracy: 0.8643 - val_loss: 0.3233 - val_accuracy: 0.8820\n",
      "Epoch 10/20\n",
      "533/533 [==============================] - 30s 56ms/step - loss: 0.3239 - accuracy: 0.8727 - val_loss: 0.3541 - val_accuracy: 0.8557\n",
      "Epoch 11/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.3096 - accuracy: 0.8749 - val_loss: 0.3291 - val_accuracy: 0.8698\n",
      "Epoch 12/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2959 - accuracy: 0.8822 - val_loss: 0.3051 - val_accuracy: 0.8804\n",
      "Epoch 13/20\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.2784 - accuracy: 0.8918 - val_loss: 0.2845 - val_accuracy: 0.8872\n",
      "Epoch 14/20\n",
      "533/533 [==============================] - 29s 55ms/step - loss: 0.2617 - accuracy: 0.8961 - val_loss: 0.2757 - val_accuracy: 0.8942\n",
      "Epoch 15/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2460 - accuracy: 0.9017 - val_loss: 0.2557 - val_accuracy: 0.8975\n",
      "Epoch 16/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2311 - accuracy: 0.9059 - val_loss: 0.2674 - val_accuracy: 0.8933\n",
      "Epoch 17/20\n",
      "533/533 [==============================] - 29s 55ms/step - loss: 0.2168 - accuracy: 0.9117 - val_loss: 0.2366 - val_accuracy: 0.9034\n",
      "Epoch 18/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.2003 - accuracy: 0.9197 - val_loss: 0.2328 - val_accuracy: 0.9069\n",
      "Epoch 19/20\n",
      "533/533 [==============================] - 28s 53ms/step - loss: 0.1877 - accuracy: 0.9236 - val_loss: 0.3378 - val_accuracy: 0.8539\n",
      "Epoch 20/20\n",
      "533/533 [==============================] - 29s 54ms/step - loss: 0.1730 - accuracy: 0.9302 - val_loss: 0.2421 - val_accuracy: 0.9034\n"
     ]
    }
   ],
   "source": [
    "#fit the model from image generator\n",
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bba7a9-86d2-4e0d-9054-d9a6529d3e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9232379794120789"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_lenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lenet5.save(\"hurricane_lenet.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bffab5-a9c4-49fe-8533-8603288bd654",
   "metadata": {},
   "source": [
    "### Alternate-Lenet-5 CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dec8147-3537-4792-896c-2175dd551f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 63, 63, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 30, 30, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPooli  (None, 14, 14, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPooli  (None, 6, 6, 128)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               2359808   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2601666 (9.92 MB)\n",
      "Trainable params: 2601666 (9.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Altlenet5 = models.Sequential()\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_Altlenet5.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128,128,3)))\n",
    "model_Altlenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_Altlenet5.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model_Altlenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_Altlenet5.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_Altlenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_Altlenet5.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model_Altlenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_Altlenet5.add(layers.Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 32 neurons\n",
    "model_Altlenet5.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Output layer: Fully connected layer with num_classes neurons (e.g., 3 )\n",
    "model_Altlenet5.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_Altlenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_Altlenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b098333-36ee-4387-9f3b-83777c0fd617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "533/533 [==============================] - 110s 205ms/step - loss: 0.4890 - accuracy: 0.7764 - val_loss: 0.4723 - val_accuracy: 0.7833\n",
      "Epoch 2/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.3274 - accuracy: 0.8679 - val_loss: 0.4917 - val_accuracy: 0.7795\n",
      "Epoch 3/20\n",
      "533/533 [==============================] - 109s 204ms/step - loss: 0.2263 - accuracy: 0.9099 - val_loss: 0.1809 - val_accuracy: 0.9315\n",
      "Epoch 4/20\n",
      "533/533 [==============================] - 107s 201ms/step - loss: 0.1723 - accuracy: 0.9301 - val_loss: 0.1670 - val_accuracy: 0.9348\n",
      "Epoch 5/20\n",
      "533/533 [==============================] - 107s 201ms/step - loss: 0.1379 - accuracy: 0.9442 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
      "Epoch 6/20\n",
      "533/533 [==============================] - 110s 206ms/step - loss: 0.1219 - accuracy: 0.9515 - val_loss: 0.1281 - val_accuracy: 0.9479\n",
      "Epoch 7/20\n",
      "533/533 [==============================] - 106s 198ms/step - loss: 0.1074 - accuracy: 0.9571 - val_loss: 0.1092 - val_accuracy: 0.9606\n",
      "Epoch 8/20\n",
      "533/533 [==============================] - 107s 201ms/step - loss: 0.1012 - accuracy: 0.9615 - val_loss: 0.1108 - val_accuracy: 0.9578\n",
      "Epoch 9/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.0919 - accuracy: 0.9648 - val_loss: 0.1259 - val_accuracy: 0.9519\n",
      "Epoch 10/20\n",
      "533/533 [==============================] - 109s 204ms/step - loss: 0.0851 - accuracy: 0.9669 - val_loss: 0.0807 - val_accuracy: 0.9693\n",
      "Epoch 11/20\n",
      "533/533 [==============================] - 104s 196ms/step - loss: 0.0764 - accuracy: 0.9703 - val_loss: 0.0778 - val_accuracy: 0.9688\n",
      "Epoch 12/20\n",
      "533/533 [==============================] - 106s 198ms/step - loss: 0.0706 - accuracy: 0.9729 - val_loss: 0.0724 - val_accuracy: 0.9716\n",
      "Epoch 13/20\n",
      "533/533 [==============================] - 107s 200ms/step - loss: 0.0671 - accuracy: 0.9743 - val_loss: 0.0765 - val_accuracy: 0.9733\n",
      "Epoch 14/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.0599 - accuracy: 0.9777 - val_loss: 0.1156 - val_accuracy: 0.9552\n",
      "Epoch 15/20\n",
      "533/533 [==============================] - 105s 196ms/step - loss: 0.0541 - accuracy: 0.9795 - val_loss: 0.0676 - val_accuracy: 0.9747\n",
      "Epoch 16/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.0503 - accuracy: 0.9810 - val_loss: 0.0659 - val_accuracy: 0.9772\n",
      "Epoch 17/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.0481 - accuracy: 0.9832 - val_loss: 0.0876 - val_accuracy: 0.9676\n",
      "Epoch 18/20\n",
      "533/533 [==============================] - 105s 197ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0589 - val_accuracy: 0.9784\n",
      "Epoch 19/20\n",
      "533/533 [==============================] - 106s 199ms/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.0622 - val_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "533/533 [==============================] - 108s 202ms/step - loss: 0.0377 - accuracy: 0.9864 - val_loss: 0.0583 - val_accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "history = model_Altlenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e93c1-441b-490a-88c3-9dccb11b410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901878833770752"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_Altlenet5.evaluate(test_rescale_ds, verbose=0)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155658c-cc48-4484-a65f-69bbf9bdcb33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_Altlenet5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_Altlenet5\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhurricane.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_Altlenet5' is not defined"
     ]
    }
   ],
   "source": [
    "model_Altlenet5.save(\"hurricane_alt.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
